{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc66e8f-84fc-4742-9ba5-f685bbeaee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.models import resnet50\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from transformers import XLNetConfig, AutoConfig\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "from torchsummary import summary\n",
    "from tensorboard.plugins import projector\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from utils.utils import *\n",
    "from utils.assignment import *\n",
    "from utils.latent_loss import *\n",
    "from model.model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4a20e-2697-4d37-9d12-28e9dfaad424",
   "metadata": {},
   "source": [
    "# Set Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d78b846-30fe-45fc-8299-51bf3eaeec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_pytorch_version(version):\n",
    "    return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "    return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fd5f7-bf5a-47cc-9155-ba3d387a5bfa",
   "metadata": {},
   "source": [
    "# DataSet & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2194d316-7e1b-4205-ba61-6a70c964ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 267, 650, 465, 317, 695, 424, 299, 426, 360, 476, 2]\n",
      "<s>the cardiac silhouette and mediastinum size are within normal limits</s>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    os.path.abspath(os.path.join('tokenizer','vocab.json')),\n",
    "    os.path.abspath(os.path.join('tokenizer','merges.txt'))\n",
    ")\n",
    "\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "print(tokenizer.encode('the cardiac silhouette and mediastinum size are within normal limits').ids)\n",
    "print(tokenizer.decode([1, 267, 650, 465, 317, 695, 424, 299, 426, 360, 476, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319f6e33-20f6-440c-939d-9c679db26c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, data, img_dir, transform, max_sentence, tokenizer, max_t): ## add max_sentence\n",
    "        self.data = data\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.max_sentence = max_sentence\n",
    "        self.max_t = max_t\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n",
    "        image = Image.open(img_path).resize((256, 256))\n",
    "        label = self.data.iloc[idx, 2]\n",
    "        \n",
    "        image = transform_img(image, self.transform)\n",
    "        _, label = tokenize_report(label)\n",
    "        if '' in label:\n",
    "            label.remove('')\n",
    "        \n",
    "        id_ = torch.zeros((self.max_sentence, self.max_t)).long()\n",
    "        for i, sent in enumerate(label):\n",
    "            input_ids = self.tokenizer.encode(sent).ids\n",
    "            for j, word in enumerate(input_ids):\n",
    "                id_[i, j] = word\n",
    "        \n",
    "        len_ = len(label)\n",
    "        len_ = torch.tensor(len_, dtype=torch.int32)\n",
    "        \n",
    "        return image[0], id_, len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0f670e-a219-45ce-9b5f-ccc9b5dc9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_clean.csv')\n",
    "df_test = pd.read_csv('data/testing_set.csv')\n",
    "\n",
    "df_train = df_train[np.logical_not(df_train.Findings == 'startseq  endseq')]\n",
    "df_test = df_test[np.logical_not(df_test.Findings == 'startseq  endseq')]\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "img_path = 'data/images'\n",
    "max_sentence = 18\n",
    "max_t = 60\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    os.path.abspath(os.path.join('tokenizer','vocab.json')),\n",
    "    os.path.abspath(os.path.join('tokenizer','merges.txt'))\n",
    ")\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "\n",
    "vocab_size = len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd821a44-f1e6-41b0-a214-9f33786f609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = XRayDataset(df_train, img_path, transform, max_sentence, tokenizer, max_t)\n",
    "test_data = XRayDataset(df_test, img_path, transform, max_sentence, tokenizer, max_t)\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d488792-378d-4cf1-881a-f1d29f568e05",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb3d572-6e9e-4fc3-b1f5-cde36541967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetPredictLSP(nn.Module):\n",
    "    def __init__(self, device, hidden_dim=384, nhead=4, nlayers=3, max_sentence=18, vocab_size=3160, pad_token_id=0, max_t=60, dropout=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cnn_text = CNN_Text_SinCos(hidden_dim=hidden_dim, device=device)\n",
    "        self.hungarian = MSEGCRLatentLoss()\n",
    "        \n",
    "        self.encoder = SentenceEncoder(pad_token_id=pad_token_id, n_hid=hidden_dim, max_t=max_t, vocab_size=vocab_size, dropout=dropout)\n",
    "        self.decoder = LSPDecoder(hidden_dim=hidden_dim, vocab_size = vocab_size, pad_token_id=pad_token_id, max_t=max_t, dropout=dropout)\n",
    "        \n",
    "        self.mlp = MLP().to(device)\n",
    "        self.mlp.load_state_dict(torch.load('model/weights/length_model_best.pt'))\n",
    "        \n",
    "        self.max_t = max_sentence\n",
    "        \n",
    "    def forward(self, X, input_id, len_, labels):\n",
    "        '''\n",
    "        X is image (bs, 3, H, W)\n",
    "        R's shape is (bs, length, hidden_dim)\n",
    "        feat will be use for the transformer decoder\n",
    "        '''\n",
    "        bs = X.shape[0]\n",
    "        R, feat = self.cnn_text(X) \n",
    "        context_series = expand_by_lengths(feat, len_)\n",
    "        \n",
    "        B = self.encoder(input_id, context_series)\n",
    "        R = flat_by_lengths(R, (torch.ones((bs))*20).to(device))\n",
    "        \n",
    "        R_pi, R_i, hung_loss = self.hungarian.forward(B, len_, R, (torch.ones(bs, dtype=int)*20).to(device))\n",
    "        \n",
    "        \n",
    "        ce_loss, logit = self.decoder(input_id, R_pi, context_series, labels)\n",
    "        \n",
    "        return logit, ce_loss, hung_loss\n",
    "    \n",
    "    def predictLSP(self, X, input_id, len_, labels):\n",
    "        bs = X.shape[0]\n",
    "        R, feat = self.cnn_text(X)\n",
    "        context_series = expand_by_lengths(feat, len_)\n",
    "        \n",
    "        B = self.encoder(input_id, context_series)\n",
    "        R = flat_by_lengths(R, (torch.ones((bs))*20).to(device))\n",
    "        \n",
    "        R_pi, R_i, hung_loss = self.hungarian.forward(B, len_, R, (torch.ones(bs, dtype=int)*20).to(device))\n",
    "        \n",
    "        return R_pi\n",
    "    \n",
    "    def text_vec(self, X, input_id, len_, labels):\n",
    "        bs = X.shape[0]\n",
    "        R, feat = self.cnn_text.evaluate(X, len_[0]) \n",
    "        \n",
    "        context_series = expand_by_lengths(feat, len_)\n",
    "        \n",
    "        B = self.encoder(input_id, context_series)\n",
    "        R = flat_by_lengths(R, len_)\n",
    "        \n",
    "        R_pi, R_i, hung_loss = self.hungarian.forward(B, len_, R, len_)\n",
    "        \n",
    "        return R_pi, context_series, hung_loss\n",
    "    \n",
    "    def decode_sentence(self, input_ids, text_vec, context_series):\n",
    "        pred = self.decoder.eval_forward(input_ids, text_vec, context_series)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc50362-f8cc-48d2-a4a1-e812ce234c68",
   "metadata": {},
   "source": [
    "# Inference with Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f2513ad5-adc9-4378-9da9-b893def5f5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SetPredictLSP(device, hidden_dim=32).to(device)\n",
    "\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load('model/weights/SetPredict_ver10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e1befb2e-4752-43c3-a855-1e745de4b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test = []\n",
    "predicted_test = []\n",
    "LSP = []\n",
    "\n",
    "for X, id_, len_ in test_loader:  # Iterate in batches over the training/test dataset.\n",
    "    label = flat_by_lengths_max_t(id_.to(device), len_.to(device), 18)\n",
    "    input_id = flat_by_lengths_max_t(id_.to(device), len_.to(device), 18)\n",
    "    X = X.to(device)\n",
    "    len_ = len_.to(device)\n",
    "\n",
    "    lsp = model.predictLSP(X, input_id, len_, label)\n",
    "    out, _, _ = model(X, input_id, len_, label)\n",
    "    \n",
    "    actual_test.append(label.cpu().detach().numpy())\n",
    "    predicted_test.append(out.cpu().detach().numpy())\n",
    "    LSP.append(lsp.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fcb7156a-8559-48e9-9865-28831db89f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = np.concatenate(predicted_test)\n",
    "actual_test = np.concatenate(actual_test)\n",
    "LSP = np.concatenate(LSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aced0dd-7229-4c5a-bea5-0390c7ed6b6d",
   "metadata": {},
   "source": [
    "## LSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa20aa57-3002-4b8a-994d-a8501367c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1937, 60, 3160) (1937, 60) (1937, 32)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_test.shape, actual_test.shape, LSP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77090073-cf1f-49ad-a4fc-efd5a5acc043",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12716/361785048.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mref_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcad_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcad\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mref_sent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mref_eos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\X-ray\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     42\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     43\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "predicted_sentences = []\n",
    "actual_sentences = []\n",
    "for id_ in range(predicted_test.shape[0]):\n",
    "    ref = actual_test[id_]\n",
    "    cad = predicted_test.argmax(axis=-1)[id_]\n",
    "\n",
    "    ref_eos = np.argwhere(ref==2).min()\n",
    "    cad_eos = np.argwhere(cad==2).min()\n",
    "\n",
    "    ref_sent = tokenizer.decode(ref[1: ref_eos])\n",
    "    cad_sent = tokenizer.decode(cad[0: cad_eos])\n",
    "    \n",
    "    predicted_sentences.append(ref_sent)\n",
    "    actual_sentences.append(cad_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30d960-7b81-4477-a149-da242b5e340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(predicted_sentences, open('predicted_sentences.pkl', 'wb'))\n",
    "pickle.dump(actual_sentences, open('actual_sentences.pkl', 'wb'))\n",
    "pickle.dump(LSP, open('lsp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebeea0-82ea-4908-80ac-0cd0e24c31f9",
   "metadata": {},
   "source": [
    "## Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbc9e3cf-ca86-4d57-83aa-91af37a7ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sentence: normal heart size and mediastinum\n",
      "Predicted Sentence: the heart size\n",
      "5.819186114595022e-155\n"
     ]
    }
   ],
   "source": [
    "id_ = 1700\n",
    "\n",
    "ref = actual_test[id_]\n",
    "cad = predicted_test.argmax(axis=-1)[id_]\n",
    "\n",
    "ref_eos = np.argwhere(ref==2).min()\n",
    "cad_eos = np.argwhere(cad==2).min()\n",
    "\n",
    "ref_sent = tokenizer.decode(ref[1: ref_eos])\n",
    "cad_sent = tokenizer.decode(cad[0: cad_eos])\n",
    "\n",
    "print(\"Actual Sentence: {}\".format(ref_sent))\n",
    "print(\"Predicted Sentence: {}\".format(cad_sent))\n",
    "\n",
    "score = sentence_bleu([ref_sent.split()], cad_sent.split())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0b4887ae-916a-42ab-84fe-81e07ebc49fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "for id_ in range(predicted_test.shape[0]):\n",
    "    ref = actual_test[id_]\n",
    "    cad = predicted_test.argmax(axis=-1)[id_]\n",
    "    if 2 not in cad:\n",
    "        cad[-1] = 2\n",
    "\n",
    "    ref_eos = np.argwhere(ref==2).min()\n",
    "    cad_eos = np.argwhere(cad==2).min()\n",
    "\n",
    "    ref_sent = tokenizer.decode(ref[1: ref_eos])\n",
    "    cad_sent = tokenizer.decode(cad[0: cad_eos])\n",
    "\n",
    "    score1 = sentence_bleu([ref_sent.split()], cad_sent.split())\n",
    "    score2 = sentence_bleu([cad_sent.split()], ref_sent.split())\n",
    "    scores1.append(score1)\n",
    "    scores2.append(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "83d56f56-d26e-445d-9c36-a3ad861c858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20303155490506922\n",
      "0.2028069926429635\n"
     ]
    }
   ],
   "source": [
    "print(np.array(scores1).mean())\n",
    "print(np.array(scores2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2eb01-fd8d-44ae-9499-9cfb2ba39bee",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d33e856e-9768-41f3-b260-7a7aa7b160df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = XRayDataset(df_train, img_path, transform, max_sentence, tokenizer, max_t)\n",
    "test_data = XRayDataset(df_test, img_path, transform, max_sentence, tokenizer, max_t)\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c51a63-7dc8-4241-bc89-70bbef3256ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SetPredictLSP(device, hidden_dim=32).to(device) ## Ver10: hidden dims' 32\n",
    "\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load('model/weights/SetPredict_ver10.pt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6271061-302f-4064-b9c5-1b81d37fbe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "predicted = []\n",
    "len_sent = []\n",
    "hung = 0\n",
    "\n",
    "\n",
    "for X, id_, len_ in test_loader:  # Iterate in batches over the training/test dataset.\n",
    "    label = flat_by_lengths_max_t(id_.to(device), len_.to(device), 18)\n",
    "    input_id = flat_by_lengths_max_t(id_.to(device), len_.to(device), 18)\n",
    "    X = X.to(device)\n",
    "    len_ = len_.to(device)\n",
    "\n",
    "    text_vec, context_series, loss_hung = model.text_vec(X, input_id, len_, label)\n",
    "    bs, _ = text_vec.shape\n",
    "    \n",
    "    ys = torch.ones(bs, 1).type(torch.long).to(device)\n",
    "    for i in range(max_t):\n",
    "        out = model.decode_sentence(ys, text_vec, context_series)\n",
    "        next_word = torch.unsqueeze(out[:, -1], 1).argmax(axis=-1)\n",
    "\n",
    "        ys = torch.cat([ys, next_word], dim=1)\n",
    "     \n",
    "    actual.append(input_id.cpu().detach().numpy())\n",
    "    predicted.append(ys.cpu().detach().numpy())\n",
    "    len_sent.append(len_.cpu().detach().numpy())\n",
    "    hung += loss_hung.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "81960cea-5d4e-4502-884d-0d83fd742b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.concatenate(predicted)\n",
    "actual = np.concatenate(actual)\n",
    "len_sent = np.concatenate(len_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61edc639-d6b7-434c-9a6a-96b1cad1d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sentence: there is no pneumothorax or pleural effusion\n",
      "Predicted Sentence: there is no pneumothorax or pleural effusion\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "id_ = 16\n",
    "\n",
    "ref = actual[id_]\n",
    "cad = predicted[id_][1:]\n",
    "\n",
    "ref_eos = np.argwhere(ref==2).min()\n",
    "cad_eos = np.argwhere(cad==2).min()\n",
    "\n",
    "ref_sent = tokenizer.decode(ref[1: ref_eos])\n",
    "cad_sent = tokenizer.decode(cad[0: cad_eos])\n",
    "\n",
    "print(\"Actual Sentence: {}\".format(ref_sent))\n",
    "print(\"Predicted Sentence: {}\".format(cad_sent))\n",
    "\n",
    "score = sentence_bleu([ref_sent.split()], cad_sent.split())\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5b5950e1-ff75-4516-9f26-14d88f90d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sent = []\n",
    "predicted_sent = []\n",
    "for id_ in range(predicted.shape[0]):\n",
    "    ref = actual[id_]\n",
    "    cad = predicted[id_][1:]\n",
    "\n",
    "    ref_eos = np.argwhere(ref==2).min()\n",
    "    cad_eos = np.argwhere(cad==2).min()\n",
    "\n",
    "    ref_sent = tokenizer.decode(ref[1: ref_eos])\n",
    "    cad_sent = tokenizer.decode(cad[0: cad_eos])\n",
    "\n",
    "    actual_sent.append(ref_sent)\n",
    "    predicted_sent.append(cad_sent)\n",
    "\n",
    "cdf = [0]\n",
    "\n",
    "for i in len_sent:\n",
    "    cdf.append(cdf[-1]+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2cc5405e-cde9-4391-ad7d-37c6158ffefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_split_sent = []\n",
    "predicted_split_sent = []\n",
    "for i, l in enumerate(cdf[:-1]):\n",
    "    start, stop = cdf[i], cdf[i+1]\n",
    "    \n",
    "    predicted_buff = []\n",
    "    actual_buff = []\n",
    "    for j in range(start, stop):\n",
    "        actual_buff.append(actual_sent[j].split())\n",
    "        predicted_buff.append(predicted_sent[j].split())\n",
    "    \n",
    "    actual_split_sent.append(actual_buff)\n",
    "    predicted_split_sent.append(predicted_buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7f56dfe-fdc6-49ff-b263-ef7ff78e23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "for actual_report, predicted_report in list(zip(actual_split_sent, predicted_split_sent)):\n",
    "    \n",
    "    for sentences in actual_report:\n",
    "        score = sentence_bleu(predicted_report, sentences)\n",
    "        scores1.append(score)\n",
    "        \n",
    "    for sentences in predicted_report:\n",
    "        score = sentence_bleu(actual_report, sentences)\n",
    "        scores2.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3048779a-f857-4d00-a1a5-192aa155f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07204745476515174\n",
      "0.07517182946437352\n"
     ]
    }
   ],
   "source": [
    "scores1 = np.array(scores1)\n",
    "scores2 = np.array(scores2)\n",
    "print(scores1.mean())\n",
    "print(scores2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce63e2-9076-4f68-abc4-4927771a791f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "X-ray_CUDA",
   "language": "python",
   "name": "x-ray_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
